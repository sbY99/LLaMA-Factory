{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fda241",
   "metadata": {},
   "source": [
    "## 학습한 모델에 대한 추론 테스트: 학습이 정상적으로 진행되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da3ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31df75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "test_option = \"postop\" # binary or delta or postop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09506d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungbinyang/anaconda3/envs/dcm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,573 >> loading file vocab.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,576 >> loading file merges.txt from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,577 >> loading file tokenizer.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,578 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,578 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,579 >> loading file tokenizer_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:44,580 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2364] 2025-11-28 08:52:44,755 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|image_processing_base.py:383] 2025-11-28 08:52:45,610 >> loading configuration file preprocessor_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:383] 2025-11-28 08:52:46,107 >> loading configuration file preprocessor_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n",
      "[INFO|image_processing_base.py:428] 2025-11-28 08:52:46,112 >> Image processor Qwen2VLImageProcessorFast {\n",
      "  \"crop_size\": null,\n",
      "  \"data_format\": \"channels_first\",\n",
      "  \"default_to_square\": true,\n",
      "  \"device\": null,\n",
      "  \"disable_grouping\": null,\n",
      "  \"do_center_crop\": null,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": null,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"input_data_format\": null,\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"pad_size\": null,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"return_tensors\": null,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 12845056,\n",
      "    \"shortest_edge\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,540 >> loading file vocab.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,541 >> loading file merges.txt from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,542 >> loading file tokenizer.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,543 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,544 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,545 >> loading file tokenizer_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2095] 2025-11-28 08:52:46,546 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|tokenization_utils_base.py:2364] 2025-11-28 08:52:46,729 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|video_processing_utils.py:726] 2025-11-28 08:52:47,401 >> loading configuration file video_preprocessor_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n",
      "[INFO|video_processing_utils.py:770] 2025-11-28 08:52:47,405 >> Video processor Qwen2VLVideoProcessor {\n",
      "  \"crop_size\": null,\n",
      "  \"data_format\": \"channels_first\",\n",
      "  \"default_to_square\": true,\n",
      "  \"device\": null,\n",
      "  \"do_center_crop\": null,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"do_sample_frames\": false,\n",
      "  \"fps\": null,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"input_data_format\": null,\n",
      "  \"max_frames\": 768,\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_frames\": 4,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"num_frames\": null,\n",
      "  \"pad_size\": null,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"return_metadata\": false,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 12845056,\n",
      "    \"shortest_edge\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2,\n",
      "  \"video_metadata\": null,\n",
      "  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\n",
      "}\n",
      "\n",
      "[INFO|processing_utils.py:1116] 2025-11-28 08:52:48,574 >> loading configuration file processor_config.json from cache at None\n",
      "[INFO|processing_utils.py:1199] 2025-11-28 08:52:48,911 >> Processor Qwen2_5_VLProcessor:\n",
      "- image_processor: Qwen2VLImageProcessorFast {\n",
      "  \"crop_size\": null,\n",
      "  \"data_format\": \"channels_first\",\n",
      "  \"default_to_square\": true,\n",
      "  \"device\": null,\n",
      "  \"disable_grouping\": null,\n",
      "  \"do_center_crop\": null,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": null,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"input_data_format\": null,\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"pad_size\": null,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"return_tensors\": null,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 12845056,\n",
      "    \"shortest_edge\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2\n",
      "}\n",
      "\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-3B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n",
      ")\n",
      "- video_processor: Qwen2VLVideoProcessor {\n",
      "  \"crop_size\": null,\n",
      "  \"data_format\": \"channels_first\",\n",
      "  \"default_to_square\": true,\n",
      "  \"device\": null,\n",
      "  \"do_center_crop\": null,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"do_sample_frames\": false,\n",
      "  \"fps\": null,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"input_data_format\": null,\n",
      "  \"max_frames\": 768,\n",
      "  \"max_pixels\": 12845056,\n",
      "  \"merge_size\": 2,\n",
      "  \"min_frames\": 4,\n",
      "  \"min_pixels\": 3136,\n",
      "  \"num_frames\": null,\n",
      "  \"pad_size\": null,\n",
      "  \"patch_size\": 14,\n",
      "  \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"return_metadata\": false,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 12845056,\n",
      "    \"shortest_edge\": 3136\n",
      "  },\n",
      "  \"temporal_patch_size\": 2,\n",
      "  \"video_metadata\": null,\n",
      "  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"processor_class\": \"Qwen2_5_VLProcessor\"\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:765] 2025-11-28 08:52:49,347 >> loading configuration file config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/config.json\n",
      "[INFO|configuration_utils.py:839] 2025-11-28 08:52:49,351 >> Model config Qwen2_5_VLConfig {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2_5_VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"dtype\": \"bfloat16\",\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"image_token_id\": 151655,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 128000,\n",
      "  \"max_window_layers\": 70,\n",
      "  \"model_type\": \"qwen2_5_vl\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 36,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"mrope_section\": [\n",
      "      16,\n",
      "      24,\n",
      "      24\n",
      "    ],\n",
      "    \"rope_type\": \"default\",\n",
      "    \"type\": \"default\"\n",
      "  },\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"text_config\": {\n",
      "    \"_name_or_path\": \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
      "    \"architectures\": [\n",
      "      \"Qwen2_5_VLForConditionalGeneration\"\n",
      "    ],\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bos_token_id\": 151643,\n",
      "    \"dtype\": \"bfloat16\",\n",
      "    \"eos_token_id\": 151645,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 2048,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 11008,\n",
      "    \"layer_types\": [\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\",\n",
      "      \"full_attention\"\n",
      "    ],\n",
      "    \"max_position_embeddings\": 128000,\n",
      "    \"max_window_layers\": 70,\n",
      "    \"model_type\": \"qwen2_5_vl_text\",\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_hidden_layers\": 36,\n",
      "    \"num_key_value_heads\": 2,\n",
      "    \"rms_norm_eps\": 1e-06,\n",
      "    \"rope_scaling\": {\n",
      "      \"mrope_section\": [\n",
      "        16,\n",
      "        24,\n",
      "        24\n",
      "      ],\n",
      "      \"rope_type\": \"default\",\n",
      "      \"type\": \"default\"\n",
      "    },\n",
      "    \"rope_theta\": 1000000.0,\n",
      "    \"sliding_window\": null,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"use_cache\": true,\n",
      "    \"use_sliding_window\": false,\n",
      "    \"vision_token_id\": 151654,\n",
      "    \"vocab_size\": 151936\n",
      "  },\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"depth\": 32,\n",
      "    \"fullatt_block_indexes\": [\n",
      "      7,\n",
      "      15,\n",
      "      23,\n",
      "      31\n",
      "    ],\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 1280,\n",
      "    \"in_channels\": 3,\n",
      "    \"in_chans\": 3,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3420,\n",
      "    \"model_type\": \"qwen2_5_vl\",\n",
      "    \"num_heads\": 16,\n",
      "    \"out_hidden_size\": 2048,\n",
      "    \"patch_size\": 14,\n",
      "    \"spatial_merge_size\": 2,\n",
      "    \"spatial_patch_size\": 14,\n",
      "    \"temporal_patch_size\": 2,\n",
      "    \"tokens_per_second\": 2,\n",
      "    \"window_size\": 112\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652,\n",
      "  \"vision_token_id\": 151654,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[WARNING|logging.py:328] 2025-11-28 08:52:49,352 >> `torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-11-28 08:52:49] llamafactory.model.model_utils.kv_cache:143 >> KV cache is enabled for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|logging.py:328] 2025-11-28 08:52:49,405 >> `torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[INFO|modeling_utils.py:1172] 2025-11-28 08:52:49,409 >> loading weights file model.safetensors from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:2341] 2025-11-28 08:52:49,414 >> Instantiating Qwen2_5_VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:986] 2025-11-28 08:52:49,417 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2341] 2025-11-28 08:52:49,418 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.bfloat16.\n",
      "[INFO|modeling_utils.py:2341] 2025-11-28 08:52:49,429 >> Instantiating Qwen2_5_VLTextModel model under default dtype torch.bfloat16.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.32it/s]\n",
      "[INFO|configuration_utils.py:941] 2025-11-28 08:52:51,726 >> loading configuration file generation_config.json from cache at /home/nas5/.cache/huggingface/hub /models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/generation_config.json\n",
      "[INFO|configuration_utils.py:986] 2025-11-28 08:52:51,728 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 1e-06\n",
      "}\n",
      "\n",
      "[INFO|dynamic_module_utils.py:423] 2025-11-28 08:52:51,938 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-VL-3B-Instruct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-11-28 08:52:52] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-11-28 08:52:52] llamafactory.model.adapter:143 >> Merged 1 adapter(s).\n",
      "[INFO|2025-11-28 08:52:52] llamafactory.model.adapter:143 >> Loaded adapter(s): saves/qwen2.5_3b_postop\n",
      "[INFO|2025-11-28 08:52:52] llamafactory.model.loader:143 >> all params: 3,754,622,976\n"
     ]
    }
   ],
   "source": [
    "from llamafactory.chat import ChatModel\n",
    "\n",
    "args = dict(\n",
    "  model_name_or_path=\"Qwen/Qwen2.5-VL-3B-Instruct\", # or full path to snapshot\n",
    "  adapter_name_or_path=f\"saves/qwen2.5_3b_{test_option}\", # load the saved LoRA adapter\n",
    "  template=\"qwen2_vl\",  # same to the one in training\n",
    "  finetuning_type=\"lora\", # same to the one in training\n",
    "  cache_dir=\"/home/nas5/.cache/huggingface/hub \"\n",
    ")\n",
    "chat_model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45b9124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('\\n<PROMPT>\\n<ROLE>\\nYou are an expert clinical reasoning AI specializing in neurosurgery, radiology, and neurology. You have deep knowledge of Degenerative Cervical Myelopathy (DCM).\\n</ROLE>\\n\\n<CLINICAL_SCENARIO>\\nYou will be provided with data for a patient with Degenerative Cervical Myelopathy (DCM) who has undergone surgical decompression. The goal is to predict their functional outcome one year after the surgery.\\nAll the data you receive was collected before the surgery, with the exception of the operative note, which is generated during the surgery. The full spectrum of potentially available data includes:\\n- Imaging Data: MR T2 Sagittal, MR T2 Axial.\\n- Text Data: Radiology reports for the MR/XR, the pre-operative admission note, and the operative note.\\n- Tabular Data: Patient demographics, past medical history, pre-operative lab results, and pre-operative symptoms.\\nFor any given patient, you will receive a subset of this data, as specified in the task. Your analysis must be based only on the data provided for that specific task.\\n</CLINICAL_SCENARIO>\\n\\n<PRIMARY_TASK>\\nYour task is to analyze the provided patient data and output a structured JSON object that predicts the 1-year post-operative JOA score.\\n</PRIMARY_TASK>\\n\\n<INSTRUCTIONS>\\nAnalyze all provided data comprehensively:\\n- Review all imaging findings, clinical data, and patient characteristics\\n- Identify factors that positively or negatively impact post-operative prognosis\\n- Synthesize information across all modalities to form an integrated assessment\\n- Consider which factors are most impactful for recovery\\n- Provide a precise integer for the post-operative JOA score (0: worst, 17: normal).\\n- Provide Rationale: Write a clear, specific, and detailed rationale that directly summarizes the most critical factors that led to that specific numerical prediction.\\n- Consider both the baseline status and expected recovery to determine the final post-operative score.\\n- The rationale should explain how the imaging findings, clinical data, surgical factors, and patient characteristics contribute to your predicted post-operative JOA score.\\n</INSTRUCTIONS>\\n\\n<OUTPUT_FORMAT>\\nYour entire output must be a single, valid JSON object. Do not include any text, greetings, or explanations outside of the JSON structure itself.\\n```json\\n{\\n  \"rationale\": \"<clear, specific, and detailed explanation>\",\\n  \"score\": <integer 0-17>\\n}\\n```\\n</OUTPUT_FORMAT>\\n</PROMPT>\\n',\n",
       " [{'content': '\\nAnalyze the following data for a patient with Degenerative Cervical Myelopathy (DCM) and predict the 1-year postoperative outcome.\\n\\n### TASK & OUTPUT FORMAT\\n\\n**TASK:**\\n1. Review all provided data within the sections below.\\n2. Provide your analysis and prediction in the strict JSON format specified in the system prompt.\\n\\n**Provided Modalities for this Task:** MR_T2S, MR_T2A, tabular, text\\n\\n<MR_T2S>\\nSlice 1: <image>\\nSlice 2: <image>\\nSlice 3: <image>\\nSlice 4: <image>\\nSlice 5: <image>\\nSlice 6: <image>\\n</MR_T2S>\\n\\n<MR_T2A>\\nSlice 1: <image>\\nSlice 2: <image>\\nSlice 3: <image>\\nSlice 4: <image>\\nSlice 5: <image>\\nSlice 6: <image>\\n</MR_T2A>\\n\\n<TABULAR_DATA>\\nBMI = 30.5, Smoking = 0, DM_duration = 60, Diabates = NA, Diabetes_with_chronic_complication = 0.0, BPH = 0.0, Parkinson = 0.0, CCI_score = 0.0, HbA1c = 7, CRP = 0.05, Hb = 12.5, Albumin = 4.1, eGFR = 105.4, Cr = 0.6, preop_joa = 15.0\\n</TABULAR_DATA>\\n\\n<TEXT_REPORTS>\\n{\\n  \"MR_REPORT\": \"**Patient ID:** [ID]  \\\\n**Patient Name:** [NAME]  \\\\n**Sex/Age:** F/84  \\\\n**Exam Date:** [DATE] (15:13:02)  \\\\n**Exam Name:** MRI of Cervical Spine (Noncontrast)  \\\\n**Order:** NONE  \\\\n**Endoscope Report:** CLO, Polyp, Biopsy  \\\\n**Addendum Report**  \\\\n\\\\n**CONCLUSION**  \\\\n**FINDING**  \\\\n**RECOMMENDATION**  \\\\n\\\\n**Report Conclusion:**  \\\\nCervical Spine MRI: A multisequence and multi-plane magnetic resonance imaging study was performed using a 3.0 T MRI scanner.  \\\\nFindings:  \\\\n- **Spondylosis** of the cervical spine.  \\\\n- **Disc degeneration** of the cervical spine.  \\\\n- **Hemangioma** at T3.  \\\\n- **C2-3:** Disc protrusion centrally with spinal cord compression.  \\\\n- **C3-4:** Disc extrusion centrally, resulting in spinal cord compression and increased signal intensity (SI) in the spinal cord \\\\u2192 **compressive myelopathy**.  \\\\n- **C4-5:** Disc protrusion centrally with spinal cord compression.  \\\\n- **C5-6:** Disc protrusion centrally with spinal cord compression.  \\\\n- **C6-7:** Disc protrusion on the left side centrally, with uncovertebral joint hypertrophy, bilateral neural foraminal narrowing.  \\\\n- **C7-T1:** Disc protrusion on the left side, mild in size (15 mm), well-circumscribed, T2 hyperintense, T1 hypointense mass lesion on the left side at the T2-3 level \\\\u2192 **Rule Out Neurogenic Tumor**.  \\\\n\\\\n**Additional Findings:**  \\\\n- **Contrast-enhanced imaging** recommended for further evaluation.  \\\\n  - **Imaging Center:** T2-3 level  \\\\n  - **Axial:** T2, T1, enhanced fat suppression T1  \\\\n  - **Coronal:** Enhanced fat suppression T1  \\\\n\\\\n**Recommendation:**  \\\\nFurther imaging with contrast medium is suggested to assess the T2-3 level lesion for potential neurogenic tumor.\",\\n  \"XR_REPORT\": \"**Information Status: Official Review Completed**  \\\\n**Report Date [DATE] (10:12:43) Add. Date [DATE]**  \\\\n**Reading Doctor [ID]/ Designated Doctor**  \\\\n**Transcription [ID] Patient ID [ID] Patient Name [NAME] Sex/Age F/84**  \\\\n**Exam Date [DATE] (17:19:35) Exam Name C-Spine A-P Right Order NONE**  \\\\n**EndoScope Report CLO Polyp Biopsy Addendum Report**  \\\\n**CONCLUSION**  \\\\n**FINDING**  \\\\n**RECOMMENDATION**  \\\\n**Report CONCLUSION**  \\\\nCervical spondylosis, decreased normal lordosis, disc space narrowing with uncovertebral joint hypertrophy at C3-4, C6-7, neural foraminal stenosis, both at C3-4 and right at C6-7.  \\\\n**FINDING**  \\\\n**RECOMMENDATION**\",\\n  \"ADMISSION_NOTE\": \"**Admission Initial Note** (DATE)  \\\\n**Department:** Orthopedics (Spine Center)  \\\\n**Attending Department:** Orthopedics (Spine Center)  \\\\n\\\\n**Chief Complaint**  \\\\n1. Weakness, extremity - 10MA  \\\\n**Admission Initial Note:** Orthopedics (Spine Center) (DATE)  \\\\n**Chief Complaint > 1. Weakness, extremity - 10MA**  \\\\n**Description**  \\\\n*Presenting Illness:* The patient presented with bilateral lower limb weakness, which began approximately 10 months prior. The patient reported difficulty walking due to decreased leg strength, which has progressively worsened. Currently, the patient can ambulate without assistance but requires hip abduction for walking. Additionally, the patient reports a tendency to lean forward while walking, fearing a fall. There is no radiation pain or numbness in the upper or lower extremities, nor is there associated weakness in the upper extremities. The patient was admitted for surgical evaluation due to these symptoms.  \\\\n\\\\n*Summary of CC and PI:*  \\\\n- Neck pain: (No)  \\\\n- Clumsy hand or upper extremity (UE) weakness: (No)  \\\\n- Gait disturbance or lower extremity (LE) weakness: (Yes), onset = 10MA  \\\\n- Bladder/bowel symptoms: (Yes): urinary frequency (+)  \\\\n- UE radicular pain: (No)  \\\\n- LE radicular pain: (No)  \\\\n- Low back pain (LBP): (No)  \\\\n\\\\n**Past Medical History > Description**  \\\\n- Diabetes Mellitus (DM): (+)  \\\\n- Hypertension (HTN): (+)  \\\\n- Tuberculosis (TBC): (-)  \\\\n- Hepatitis: (-)  \\\\n- Previous surgery: (+) 40YA: Removal of a uterine fibroid.  \\\\n\\\\n**Social History > Description**  \\\\n.  \\\\n**Family History > Description**  \\\\n.  \\\\n**Review of Systems > Description**  \\\\n- Family history: (-/-)  \\\\n- Childbirth: (-/-/-)  \\\\n\\\\n**Physical Examination > Description**  \\\\n*Standing-related*  \\\\n- Wide-based stance: (Yes)  \\\\n- Difficulty in standing against push to (Backward / Forward / Right / Left): ( + / + / + / + )  \\\\n- Romberg test: (-)  \\\\n\\\\n*Gait-related*  \\\\n- Gait disturbance: wide-based, slow gait  \\\\n- Wide-based gait: ( + / + )  \\\\n- Turning difficulty: ( + / + )  \\\\n- Tandem gait: Not performed.  \\\\n- Difficulty in stepping up: ( + / + )  \\\\n\\\\n- Grip & release test (full flex ~ full extension: number/10 seconds): (20 / 20)  \\\\n- Finger escape (finger abduction or flexion/30 seconds): (- / -)  \\\\n\\\\n- Buttoning difficulty: (-)  \\\\n- Difficulty in using chopsticks: (-)  \\\\n- Writing difficulty: (-)  \\\\n\\\\n- Bladder symptoms: urinary frequency (+)  \\\\n- Bowel symptoms: none  \\\\n- L\\\\u2019Hermitte sign: none  \\\\n\\\\n- Occipital neuralgia: (0 / 0)  \\\\n- Spurling sign: (- / -)  \\\\n- Shoulder abduction pain relief sign: (- / -)  \\\\n- Axial compression test: (- / -)  \\\\n- Straight leg raise (SLR): (90 / 90)  \\\\n- Femoral nerve stretching test (FNST): (- / -)  \\\\n- Kemp sign: (- / -)  \\\\n\\\\n- Heel standing difficulty: ( + / + )  \\\\n- Tip toeing difficulty: ( + / + )  \\\\n- T sign: ( + / + )  \\\\n- Note: All tests above demonstrate instability and difficulty maintaining balance.  \\\\n\\\\n- Claudication: none  \\\\n- Midline tenderness (MLT): (-)  \\\\n- Paravertebral muscle tenderness (PVMT): (- / -)  \\\\n\\\\n*Sensory*  \\\\n- C2: (100 / 100)  \\\\n- C3: (100 / 100)  \\\\n- C4: (100 / 100)  \\\\n- C5: (100 / 100)  \\\\n- C6: (100 / 100)  \\\\n- C7: (100 / 100)  \\\\n- C8: (100 / 100)  \\\\n- T1: (100 / 100)  \\\\n- T2-T12: (100 / 100)  \\\\n- L1: (100 / 100)  \\\\n- L2: (100 / 100)  \\\\n- L3: (100 / 100)  \\\\n- L4: (100 / 100)  \\\\n- L5: (100 / 100)  \\\\n- S1: (100 / 100)  \\\\n\\\\n*Motor*  \\\\n- Shoulder abductor (C5): 5 / 5  \\\\n- Elbow flexor (C5 > C6): 5 / 4+  \\\\n- Wrist extensor (C6): 5 / 4  \\\\n- Elbow extensor (C7): 5 / 4+  \\\\n- Wrist flexor (C7): 5 / 4+  \\\\n- Finger (IP joints) flexor (C8): 5 / 5  \\\\n- Finger abduction (T1): 5 / 5  \\\\n- Hip flexor (L2): 4 / 4  \\\\n- Hip abductor (L5): 4+ / 4  \\\\n- Knee extensor (L3): 5 / 5  \\\\n- Ankle dorsiflexor (L4 > L5): 5 / 5  \\\\n- Great toe extensor (L5): 5 / 5  \\\\n- Ankle plantarflexor (S1): 5 / 5  \\\\n- Great toe flexor (S1): 5 / 5  \\\\n\\\\n*Upper Extremity Reflexes*  \\\\n- Biceps jerk: (++ / ++)  \\\\n- Brachioradialis jerk: (++ / ++)  \\\\n- Triceps jerk: (++ / ++)  \\\\n- Inverted radial reflex: (+ / +)  \\\\n- Hoffmann reflex: (+ / +)  \\\\n- Scapulohumeral reflex: (- / -)  \\\\n\\\\n*Lower Extremity Reflexes*  \\\\n- Knee jerk: (++ / ++)  \\\\n- Ankle jerk: (++ / ++)  \\\\n- Ankle clonus (sustained, unsustained, -): (- / -)  \\\\n- Babinski: (- / -)  \\\\n\\\\n*Impaired proprioception for the great toe flex/ext (+=impaired, -=normal): (- / +)*  \\\\n\\\\n*Circulation*  \\\\n- Radial artery: intact and symmetric  \\\\n- Ulnar artery: intact and symmetric  \\\\n- Posterior tibial artery: intact and symmetric  \\\\n- Dorsalis pedis artery: intact and symmetric  \\\\n\\\\n**Assessment > Description**  \\\\nCervical myelopathy  \\\\n\\\\n**Plan > Description**  \\\\nPosterior laminectomy and fusion, C3-4  \\\\nStaged anterior cervical discectomy and fusion (ACDF)\",\\n  \"OPERATIVE_NOTE\": \"**Surgical Note**  \\\\n**Date of Surgery (MM/DD/YY):** 04/20/10  \\\\n**Preoperative Diagnosis:**  \\\\n1. Compressive myelopathy, C3-4  \\\\n2. Spinal stenosis, C2-T1  \\\\n**Postoperative Diagnosis:**  \\\\n1. Compressive myelopathy, C3-4  \\\\n2. Spinal stenosis, C2-T1  \\\\n**Name of Operation:**  \\\\n1. Posterior decompression of the cervical spine, C3-4-5  \\\\n2. Posterior instrumentation with fusion using bone graft (iliac bone and local bone), C3-4-5  \\\\n**Operative Findings:**  \\\\n1. Severe narrowing of the cervical spinal canal was observed, with the dural sac compressed.  \\\\n2. After decompression, the spinal cord was released at the C2-3-4-5 levels, and dural pulsation was confirmed.  \\\\n3. The bilateral foramina at the C3-4-5 levels were found to be free compared to the central canal.  \\\\n4. No intraoperative findings of dural tear were noted.  \\\\n**Operative Procedure:**  \\\\nUnder general anesthesia, the patient was positioned in the prone position. Standard techniques were used for skin preparation and draping of the cervical spine. A C-arm was utilized to confirm the C4-5 level, followed by a midline longitudinal skin incision above and below this level. The fascia was divided, and the paraspinal muscles were detached from the spinous process and interspinous ligament to expose the spinous process. Subperiosteal dissection was performed to expose the C3-4-5-6 facet joints. The spinous processes of the C3, C4, and C5 vertebrae were removed. During decompression, care was taken to avoid cord compression and dural tear, with a burr used to remove the laminae of the C3, C4, and C5 vertebrae. Additional decompression was performed using punches around the spinal cord. Local bone harvested during decompression was prepared as chip bone. Cancellous and cortical bone was harvested from the right iliac crest for bone grafting and prepared as chip bone. Three K-wires were inserted into the left lateral masses of the C3, C4, and C5 vertebrae, and the lateral mass screw insertion sites were confirmed using a C-arm. Based on this, three lateral mass screws were inserted. The lateral mass was decorticated using a burr to prepare the site for bone grafting. A rod was bent to match the cervical lordosis and instrumentation was performed on the left lateral mass screws. The previously prepared chip bone and Bongross HA were mixed and placed into the decorticated site for bone grafting. The same sequence was repeated for the right side of C3-4-5. Copious irrigation and meticulous hemostasis were performed, followed by the insertion of two Hemo-vac drains. Thrombin was applied to ensure effective hemostasis. A single JP drain was placed at the iliac bone harvest site. The wound was closed in layers and dressed with an occlusive dressing to complete the procedure.\"\\n}\\n</TEXT_REPORTS>\\n',\n",
       "   'role': 'user'}],\n",
       " '{\"rationale\": \"Based on the provided imaging and clinical data, the predicted post-operative JOA score is 14.0.\", \"score\": 14}')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = read_json_file(f\"data/dcm_{test_option}_only.json\")\n",
    "system_prompt = test_dataset[0]['messages'][0]['content'] # LLaMA Factory 특성상, 시스템 프롬프트 분리\n",
    "input_messages = [test_dataset[0]['messages'][1]]\n",
    "output = test_dataset[0]['messages'][2]['content']\n",
    "images = [p.replace(\"../../\",\"../\") for p in test_dataset[0]['images']] # 테스트 환경 경로에 맞게 전처리\n",
    "\n",
    "print(\"Test Sample:\")\n",
    "system_prompt, input_messages, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb403abd",
   "metadata": {},
   "source": [
    "### 성능 테스트 목적이 아니므로 샘플 한 개로 학습때 먹인 label 형태가 나오는지 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b296803",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_model.chat(system=system_prompt, messages=input_messages, images=images)[0].response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c0ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rationale': 'Based on the provided imaging and clinical data, the predicted 1-year post-operative JOA score is 15.', 'score': 15}\n"
     ]
    }
   ],
   "source": [
    "clean_response = response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "response_json = json.loads(clean_response)\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c5fe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rationale\": \"Based on the provided imaging and clinical data, the predicted post-operative JOA score is 14.0.\", \"score\": 14}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
